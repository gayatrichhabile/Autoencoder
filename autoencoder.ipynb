{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Autoencoder\nWiki: https://en.wikipedia.org/wiki/Autoencoder\n\nCode source: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/autoencoder.py\n\nMNIST Dataset: http://yann.lecun.com/exdb/mnist/\n\nReferences: Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n\n## Introduction\nAn autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name. Several variants exist to the basic model, with the aim of forcing the learned representations of the input to assume useful properties.\n\n<img src=\"https://s2.ax1x.com/2019/10/07/uWpcad.png\" alt=\"drawing\" width=\"400\"/>\n\n\n## Structure\nAn autoencoder consists of two parts, the encoder and the decoder, which can be defined as transitions $\\phi$ and $\\psi$, such that:\n\n$$\\phi: x \\rightarrow h, h = \\phi(x)$$\n\n$$\\psi: h \\rightarrow \\tilde{x}, \\tilde{x} = \\psi (h)$$\n\n$$\\phi ,\\psi ={\\underset{\\phi ,\\psi }{\\operatorname {arg\\,min} }}\\,\\sum_{i=1}^N ||x_i - \\psi (\\phi (x_i)) ||^2$$\n\nIn the simplest case,\n$$ h =\\sigma (Wx + b)$$\n\nEmbedding $h$ is usually referred to as code, latent variables, or latent representation. Here, $\\sigma$ is an element-wise activation function such as a sigmoid function or a rectified linear unit. $W$ is a weight matrix and $b$ is a bias vector. Weights and biases are usually initialized randomly, and then updated iteratively during training through Backpropagation. After that, the decoder stage of the autoencoder maps $h$ to the reconstruction $\\tilde{x}$ of the same shape as $x$:\n\n$$\\tilde{x} = \\sigma (\\tilde{W}h +\\tilde{b})$$\nwhere $\\tilde{W}$, $\\tilde{b}$ for the decoder may be unrelated to the corresponding $W$, $b$ for the encoder.\n\nAutoencoders are trained to minimise reconstruction errors (such as squared errors), often referred to as the \"loss\":\n$$L(X, \\tilde{X})=\\sum_{i=1}^N||x_i -\\tilde{x}_i||^2$$\n\nAs mentioned before, the training of an autoencoder is performed through Backpropagation of the error, just like a regular feedforward neural network."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Import MNIST data\nmnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nmnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nx_train = np.array(mnist_train.iloc[:, 1:]).reshape(-1, 28*28) / 255\n# y_train = np.array(mnist_train.iloc[:, 0])\nx_test = np.array(mnist_test.iloc[:, 1:]).reshape(-1, 28*28) / 255\n# y_test = np.array(mnist_test.iloc[:, 0])\nn_train_samples = x_train.shape[0]\n\n# Network Parameters\nnum_hidden_1 = 256 # 1st layer num features\nnum_hidden_2 = 128 # 2nd layer num features (the latent dim)\nnum_input = 784 # MNIST data input (img shape: 28*28)\n\n# tf Graph input (only pictures)\nX = tf.placeholder(\"float\", [None, num_input])\n\nweights = {\n    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2])),\n    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1])),\n    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n}\nbiases = {\n    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2])),\n    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n    'decoder_b2': tf.Variable(tf.random_normal([num_input])),\n}\n\n# Building the encoder\ndef encoder(x):\n    # Encoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n    # layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n    \n    # Encoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n    return layer_2\n\n# Building the decoder\ndef decoder(x):\n    # Decoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n    # layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n    \n    # Decoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n    return layer_2\n\n# Construct model\nembedding = encoder(X)\nrecon_x = decoder(embedding)\n\n# Prediction\ny_pred = recon_x\n# Targets (Labels) are the input data.\ny_true = X\n\n# Define loss and optimizer, minimize the squared error\nloss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\nlearning_rate = tf.placeholder(\"float32\")\noptimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n\nprint('Autoencoder is constructed.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSProp: https://en.wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp\n\nRMSProp (for Root Mean Square Propagation) is also a method in which the learning rate is adapted for each of the parameters. The idea is to divide the learning rate for a weight by a running average of the magnitudes of recent gradients for that weight. So, first the running average is calculated in terms of means square,\n$$v(w,t):=\\gamma v(w,t-1)+(1-\\gamma )(\\nabla Q_{i}(w))^{2}$$\nwhere, $\\gamma$ is the forgetting factor.\n\nAnd the parameters are updated as,\n\n$$w:=w-{\\frac {\\eta }{\\sqrt {v(w,t)}}}\\nabla Q_{i}(w)$$\n\nRMSProp has shown excellent adaptation of learning rate in different applications. RMSProp can be seen as a generalization of Rprop and is capable to work with mini-batches as well opposed to only full-batches."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Parameters\nlearning_rate_AE = 0.01\nmax_epoch = 10000\n# max_epoch = 50000\nbatch_size = 256\n\ndisplay_step = 1000\n\n# Start Training\n# Start a new TF session\nwith tf.Session() as sess:\n    # Initialize the variables (i.e. assign their default value)\n    sess.run(tf.global_variables_initializer())\n\n    # Training\n    for i in range(max_epoch):\n        # Prepare a batch\n        tmp_index = np.random.permutation(n_train_samples)\n        batch_x = x_train[tmp_index[:batch_size], :]\n        # Run optimization op (backprop) and cost op (to get loss value)\n        _, l = sess.run([optimizer, loss], feed_dict={X:batch_x, learning_rate:learning_rate_AE})\n        # Display logs per step\n        if i % display_step == 0:\n            print('Step %i: Minibatch Loss: %f' % (i, l))\n\n    # Testing\n    # Encode and decode images from test set and visualize their reconstruction.\n    n = 4\n    img_orig = np.empty((28 * n, 28 * n))\n    img_recon = np.empty((28 * n, 28 * n))\n    for i in range(n):\n        # MNIST test set\n        batch_x = x_test[i*n:(i+1)*n, :]\n        # Encode and decode the digit image\n        g = sess.run(recon_x, feed_dict={X:batch_x})\n\n        # Display original images\n        for j in range(n):\n            # Draw the original digits\n            img_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = batch_x[j].reshape([28, 28])\n        # Display reconstructed images\n        for j in range(n):\n            # Draw the reconstructed digits\n            img_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n\n    print(\"Original Images\")\n    plt.figure(figsize=(n, n))\n    plt.imshow(img_orig, origin=\"upper\", cmap=\"gray\")\n    plt.show()\n\n    print(\"Reconstructed Images\")\n    plt.figure(figsize=(n, n))\n    plt.imshow(img_recon, origin=\"upper\", cmap=\"gray\")\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}